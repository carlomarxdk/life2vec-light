{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define the Populations\n",
    "First, we use `src\\dataloaders\\populations\\users.py` to define the Population object. Here, we \n",
    "1. provide a **raw** input file containing some information about the users (for example, some kind of demographic information as birthday),\n",
    "2. preprocess and filter users based on soem criteria (for example, you want to exclude people beyond certain age),\n",
    "3. create data splits (train, val, test).\n",
    "\n",
    "As you create the object and call specific methods, the Population object runs all these processes and saves outputs in `data\\processed\\populations` folder. \n",
    "\n",
    "### Why do we need the Populations object?\n",
    "\n",
    "It defines cohort of users that we want to work with.\n",
    "Based on the populations, we further create a dataset that contains specific cohorts of people. You can define multiple populations and create various datasets based on various specifications of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Population object\n",
    "from src.dataloaders.populations.users import UserPopulation\n",
    "users = UserPopulation()\n",
    "## run the preprocessing part\n",
    "users.population()\n",
    "## create datasplits \n",
    "users.data_split()\n",
    "## You can also just run the prepare function to do both of the above steps\n",
    "users.prepare() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run these commands for the first time, you will see that the results are saved in `data\\procesed\\populations`. \n",
    "Next time you the same functions, instead of calculating everything, the object would read the data from the `data\\processed\\populations` folder. **This is important for very big datasets**.\n",
    "\n",
    "If you want to redo the calculations, you need to empty the `data\\processed\\populations` folder. It also applies to cases, when you change the code of the `src\\dataloaders\\populations\\users.py`, as the Population object saves `arguments` so it can validate that you call a specific version of the Population object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the Source\n",
    "The Source objects in `src\\data\\sources` specify how to process a specific *source* of data (for example, the dummy labor dataset). Inside of this object we specify how to preprocess and tokenie the dataset. \n",
    "\n",
    "#### What does a Source do?\n",
    "The Source specifies how to process a specific type of the input data. For example, `SyntheticLaborSource` (in `src\\dataloaders\\sources`) specifies how to process the `data\\rawdata\\synth_labor.csv`.\n",
    "\n",
    "#### Why do we need a Source?\n",
    "It makes it easier to process data from different data streams (or datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.sources.synth_labor import SyntheticLaborSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to create a SOURCE!\n",
    "synth_labor = SyntheticLaborSource()\n",
    "## process the raw file (and maybe do some preprocessing)\n",
    "synth_labor.parsed()\n",
    "## index the files\n",
    "synth_labor.indexed()\n",
    "## tokenize the files\n",
    "synth_labor.tokenized()\n",
    "### Or use the prepare function to do all of the above\n",
    "synth_labor.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run these commands for the first time, you will see that the results are saved in `data\\procesed\\sources`. \n",
    "Next time you the same functions, instead of calculating everything, the object would read the data from the `data\\processed\\sources` folder. **This is important for very big datasets**.\n",
    "\n",
    "If you want to redo the calculations, you need to empty the *corresponding* file in the `data\\processed\\sources` folder. It also applies to cases, when you change the code of the `src\\dataloaders\\sources\\synth_labor.py`, as the `SyntheticLaborSource` object saves `arguments` so it can validate that you call it on future runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Corpus\n",
    "Now we can reuse both `Populations` and `Source` objects to actually create a dataset. It happens in `src\\dataloaders\\datamodule.py`.\n",
    "\n",
    "For the pretraining, we can use `L2VDataModule` in `src\\dataloaders\\datamodule.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.datamodule import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(population=users, sources=[synth_labor], name=\"synthetic\")\n",
    "corpus.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORD_DATE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>BIRTHDAY</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AFTER_THRESHOLD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USER_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>INCOME_45 CITY_6 OCC_29 IND_32</td>\n",
       "      <td>1957-06-25</td>\n",
       "      <td>Male</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271</td>\n",
       "      <td>INCOME_21 CITY_18 OCC_91 IND_20</td>\n",
       "      <td>1957-06-25</td>\n",
       "      <td>Male</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284</td>\n",
       "      <td>INCOME_2 CITY_21 OCC_29 IND_18</td>\n",
       "      <td>1957-06-25</td>\n",
       "      <td>Male</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>INCOME_31 CITY_17 OCC_93 IND_15</td>\n",
       "      <td>1957-06-25</td>\n",
       "      <td>Male</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326</td>\n",
       "      <td>INCOME_2 CITY_3 OCC_48 IND_17</td>\n",
       "      <td>1957-06-25</td>\n",
       "      <td>Male</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RECORD_DATE                         SENTENCE   BIRTHDAY   SEX  AGE  \\\n",
       "USER_ID                                                                       \n",
       "1                122   INCOME_45 CITY_6 OCC_29 IND_32 1957-06-25  Male   63   \n",
       "1                271  INCOME_21 CITY_18 OCC_91 IND_20 1957-06-25  Male   63   \n",
       "1                284   INCOME_2 CITY_21 OCC_29 IND_18 1957-06-25  Male   63   \n",
       "1                292  INCOME_31 CITY_17 OCC_93 IND_15 1957-06-25  Male   63   \n",
       "1                326    INCOME_2 CITY_3 OCC_48 IND_17 1957-06-25  Male   63   \n",
       "\n",
       "         AFTER_THRESHOLD  \n",
       "USER_ID                   \n",
       "1                  False  \n",
       "1                  False  \n",
       "1                  False  \n",
       "1                  False  \n",
       "1                  False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.combined_sentences(split=\"train\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a vocabulary\n",
    "The `Vocabulary` object - it removes words that do not appear too much for example. For example, you can see since we defined *Income* feature as `Binned` in the `SyntheticLaborSource` - it become binned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.vocabulary import CorpusVocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CorpusVocabulary(corpus, name=\"synthetic\")\n",
    "vocab.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.datamodule import L2VDataModule\n",
    "from src.dataloaders.tasks.pretrain import MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the task we are going to use with the data\n",
    "task = MLM(name=\"pretrain\", max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On the first initialization of the datamodule, we do not have a vocabulary object\n",
    "datamodule = L2VDataModule(corpus, batch_size=32, task=task, vocabulary=vocab, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORE ANNOTATIONS TO COME"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
