{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define the Populations\n",
    "First, we use `src\\dataloaders\\populations\\users.py` to define the Population object. Here, we \n",
    "1. provide a **raw** input file containing some information about the users (for example, some kind of demographic information as birthday),\n",
    "2. preprocess and filter users based on soem criteria (for example, you want to exclude people beyond certain age),\n",
    "3. create data splits (train, val, test).\n",
    "\n",
    "As you create the object and call specific methods, the Population object runs all these processes and saves outputs in `data\\processed\\populations` folder. \n",
    "\n",
    "### Why do we need the Populations object?\n",
    "\n",
    "It defines cohort of users that we want to work with.\n",
    "Based on the populations, we further create a dataset that contains specific cohorts of people. You can define multiple populations and create various datasets based on various specifications of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Population object\n",
    "from src.dataloaders.populations.users import UserPopulation\n",
    "users = UserPopulation()\n",
    "## run the preprocessing part\n",
    "users.population()\n",
    "## create datasplits \n",
    "users.data_split()\n",
    "## You can also just run the prepare function to do both of the above steps\n",
    "users.prepare() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run these commands for the first time, you will see that the results are saved in `data\\procesed\\populations`. \n",
    "Next time you the same functions, instead of calculating everything, the object would read the data from the `data\\processed\\populations` folder. **This is important for very big datasets**.\n",
    "\n",
    "If you want to redo the calculations, you need to empty the `data\\processed\\populations` folder. It also applies to cases, when you change the code of the `src\\dataloaders\\populations\\users.py`, as the Population object saves `arguments` so it can validate that you call a specific version of the Population object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the Source\n",
    "The Source objects in `src\\data\\sources` specify how to process a specific *source* of data (for example, the dummy labor dataset). Inside of this object we specify how to preprocess and tokenie the dataset. \n",
    "\n",
    "#### What does a Source do?\n",
    "The Source specifies how to process a specific type of the input data. For example, `SyntheticLaborSource` (in `src\\dataloaders\\sources`) specifies how to process the `data\\rawdata\\synth_labor.csv`.\n",
    "\n",
    "#### Why do we need a Source?\n",
    "It makes it easier to process data from different data streams (or datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.sources.synth_labor import SyntheticLaborSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to create a SOURCE!\n",
    "synth_labor = SyntheticLaborSource()\n",
    "## process the raw file (and maybe do some preprocessing)\n",
    "synth_labor.parsed()\n",
    "## index the files\n",
    "synth_labor.indexed()\n",
    "## tokenize the files\n",
    "synth_labor.tokenized()\n",
    "### Or use the prepare function to do all of the above\n",
    "synth_labor.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run these commands for the first time, you will see that the results are saved in `data\\procesed\\sources`. \n",
    "Next time you the same functions, instead of calculating everything, the object would read the data from the `data\\processed\\sources` folder. **This is important for very big datasets**.\n",
    "\n",
    "If you want to redo the calculations, you need to empty the *corresponding* file in the `data\\processed\\sources` folder. It also applies to cases, when you change the code of the `src\\dataloaders\\sources\\synth_labor.py`, as the `SyntheticLaborSource` object saves `arguments` so it can validate that you call it on future runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Corpus\n",
    "Now we can reuse both `Populations` and `Source` objects to actually create a dataset. It happens in `src\\dataloaders\\datamodule.py`.\n",
    "\n",
    "For the pretraining, we can use `L2VDataModule` in `src\\dataloaders\\datamodule.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.datamodule import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(population=users, sources=[synth_labor], name=\"synthetic\")\n",
    "corpus.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.combined_sentences(split=\"train\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a vocabulary\n",
    "The `Vocabulary` object - it removes words that do not appear too much for example. For example, you can see since we defined *Income* feature as `Binned` in the `SyntheticLaborSource` - it become binned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.vocabulary import CorpusVocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CorpusVocabulary(corpus, name=\"synthetic\")\n",
    "vocab.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.datamodule import L2VDataModule\n",
    "from src.dataloaders.tasks.pretrain import MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the task we are going to use with the data\n",
    "task = MLM(name=\"pretrain\", \n",
    "           max_length=200,\n",
    "           no_sep = False, \n",
    "           # Augmentation\n",
    "            p_sequence_timecut = 0.0,\n",
    "            p_sequence_resample = 0.01,\n",
    "            p_sequence_abspos_noise = 0.1,\n",
    "            p_sequence_hide_background = 0.01,\n",
    "            p_sentence_drop_tokens = 0.01,\n",
    "            shuffle_within_sentences = True,\n",
    "            # MLM specific options\n",
    "            mask_ratio = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On the first initialization of the datamodule, we do not have a vocabulary object\n",
    "datamodule = L2VDataModule(corpus, batch_size=32, task=task, vocabulary=vocab, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORE ANNOTATIONS TO COME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Add model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use code from the experiments\n",
    "from src.models.pretrain import TransformerEncoder\n",
    "import argparse\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams(argparse.Namespace):\n",
    "  hidden_size = 96 #size of the hidden layers and embeddings\n",
    "  hidden_ff = 512 #size of the position-wise feed-forward layer\n",
    "  n_encoders = 4 # number of encoder blocks\n",
    "  n_heads = 8 # number of attention heads in the multiheadattention module\n",
    "  n_local = 2 # number of local attention heads \n",
    "  local_window_size = 4 # size of the window for local attention\n",
    "  max_length = 100 # maximum length of the input sequence\n",
    "  vocab_size = 100 # size of the vocabulary\n",
    "  num_classes = 3 # number of classes for the SOP class (we have 3: original, reversed, shuffled)\n",
    "  lr = 0.001\n",
    "  batch_size = 4\n",
    "  num_epochs = 30\n",
    "  device = 'cuda'\n",
    "  attention_type = \"performer\"\n",
    "  norm_type = \"rezero\"\n",
    "  num_random_features = 32 # number of random features for the Attention module (Performer uses this)\n",
    "  parametrize_emb = True # whether to center the token embeddin matrix\n",
    "  \n",
    "  emb_dropout = 0.1 #dropout for the embedding block\n",
    "  fw_dropout = 0.1 #dropout for the position-wise feed-forward layer\n",
    "  att_dropout = 0.1 # dropout for the multiheadattention module\n",
    "  hidden_act = \"swish\" # activation function for the hidden layers (attention layers use ReLU)\n",
    "  optimizer = \"adam\" # optimizer to use\n",
    "hparams=Hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"hidden_size\": 96,  # size of the hidden layers and embeddings\n",
    "    \"hidden_ff\": 512,  # size of the position-wise feed-forward layer\n",
    "    \"n_encoders\": 4,  # number of encoder blocks\n",
    "    \"n_heads\": 8,  # number of attention heads in the multiheadattention module\n",
    "    \"n_local\": 2,  # number of local attention heads\n",
    "    \"local_window_size\": 4,  # size of the window for local attention\n",
    "    \"max_length\": task.max_length,  # maximum length of the input sequence\n",
    "    \"vocab_size\": vocab.size(),  # size of the vocabulary\n",
    "    \"num_classes\": \"\",  \n",
    "    \"cls_num_targs\": 3, # number of classes for the SOP class (we have 3: original, reversed, shuffled)\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 4,\n",
    "    \"num_epochs\": 30,\n",
    "    \"device\": 'cuda',\n",
    "    \"attention_type\": \"performer\",\n",
    "    \"norm_type\": \"rezero\",\n",
    "    \"num_random_features\": 32,  # number of random features for the Attention module (Performer uses this)\n",
    "    \"parametrize_emb\": True,  # whether to center the token embedding matrix\n",
    "    \"emb_dropout\": 0.1,  # dropout for the embedding block\n",
    "    \"fw_dropout\": 0.1,  # dropout for the position-wise feed-forward layer\n",
    "    \"att_dropout\": 0.1,  # dropout for the multiheadattention module\n",
    "    \"dc_dropout\": 0.1,  # dropout for the decoder block\n",
    "    \"hidden_act\": \"swish\",  # activation function for the hidden layers (attention layers use ReLU)\n",
    "    \"optimizer\": \"adam\",  # optimizer to use\n",
    "    \"training_task\": \"mlm\",\n",
    "    \"weight_tying\": True,\n",
    "    \"norm_output_emb\": True,\n",
    "    \"epsilon\": 1e-8,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2v = TransformerEncoder(hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=hparams[\"num_epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=l2v, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More annotations to come."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
